{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run_model_toy06\n",
    "\n",
    "From https://github.com/tardis-sn/tardis-setups/tree/master/rad_trans_models with some changes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = '20d'\n",
    "ATOM_DATA = 'kurucz_cd23_latest.h5'             # in ~/Downloads/tardis-data\n",
    "PICKLE_DIR = '/storage/epassaro/Toy_06/kurucz'  # where to dump pickled sims\n",
    "NTHREADS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy import units as u\n",
    "from tardis import run_tardis\n",
    "from tardis.io.config_reader import Configuration\n",
    "from tardis.simulation import Simulation\n",
    "from tardis.util.base import parse_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(PICKLE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbols = np.array([3.05e+42, 8.91e+42, 1.10e+43, 1.00e+43])*u.erg/u.s\n",
    "final_params = {'5d':  (5*u.d, lbols[0],  20500.*u.km/u.s), \n",
    "                '10d': (10*u.d, lbols[1], 17000.*u.km/u.s), \n",
    "                '15d': (15*u.d, lbols[2], 10000.*u.km/u.s), \n",
    "                '20d': (20*u.d, lbols[3],  5500.*u.km/u.s),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_remove_bracket = re.compile('\\[.+\\]')\n",
    "t0_pattern = re.compile('tend = (.+)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_blondin_toymodel(fname):\n",
    "\n",
    "    with open(fname, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#idx\"):\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError('File {0} does not conform to Toy Model format as it does not contain #idx')\n",
    "            \n",
    "    columns = [pattern_remove_bracket.sub('', item) for item in line[1:].split()]\n",
    "\n",
    "    raw_blondin_csv =  pd.read_csv(fname, delim_whitespace=True, comment='#', header=None, names=columns)\n",
    "    raw_blondin_csv.set_index('idx', inplace=True)\n",
    "\n",
    "    blondin_csv = raw_blondin_csv.loc[:, ['vel', 'dens', 'temp', 'X_56Ni0', 'X_Ti', 'X_Ca', 'X_S', 'X_Si', 'X_O', 'X_C']]\n",
    "    rename_col_dict = {'vel': 'velocity', 'dens': 'density', 'temp': 't_rad'}\n",
    "    rename_col_dict.update({item:item[2:] for item in blondin_csv.columns[3:]})\n",
    "    rename_col_dict['X_56Ni0'] = 'Ni56'\n",
    "    blondin_csv.rename(columns=rename_col_dict, inplace=True)\n",
    "    blondin_csv.iloc[:, 3:] = blondin_csv.iloc[:,3:].divide(blondin_csv.iloc[:,3:].sum(axis=1), axis=0)\n",
    "\n",
    "    # changing velocities to outer boundary\n",
    "    new_velocities = 0.5 * (blondin_csv.velocity.iloc[:-1].values + blondin_csv.velocity.iloc[1:].values)\n",
    "    new_velocities = np.hstack((new_velocities, [2 * new_velocities[-1] - new_velocities[-2]]))\n",
    "    blondin_csv['velocity'] = new_velocities\n",
    "\n",
    "    with open(fname, 'r') as f:\n",
    "        t0_string = t0_pattern.findall(f.read())[0]\n",
    "\n",
    "    t0 = parse_quantity(t0_string.replace('DAYS', 'day'))\n",
    "    \n",
    "    blondin_dict = {}\n",
    "    blondin_dict['model_density_time_0'] = str(t0)\n",
    "    blondin_dict['description'] = 'Converted {0} to csvy format'.format(fname)\n",
    "    blondin_dict['tardis_model_config_version'] = 'v1.0'\n",
    "    blondin_dict_fields = [dict(name='velocity', unit='km/s', desc='velocities of shell outer bounderies.')]\n",
    "    blondin_dict_fields.append(dict(name='density', unit='g/cm^3', desc='mean density of shell.'))\n",
    "    blondin_dict_fields.append(dict(name='t_rad', unit='K', desc='radiative temperature.'))\n",
    "\n",
    "    for abund in blondin_csv.columns[3:]:\n",
    "        blondin_dict_fields.append(dict(name=abund, desc='Fraction {0} abundance'.format(abund)))\n",
    "    blondin_dict['datatype'] = {'fields':blondin_dict_fields}\n",
    "\n",
    "    return blondin_dict, blondin_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_final_models_plus_pickle(params, fname, atom_data, nthreads, pickle_dir):\n",
    "    \n",
    "    model_config = Configuration.from_yaml(fname)\n",
    "    model_config.montecarlo.nthreads = nthreads\n",
    "    model_config.atom_data = atom_data\n",
    "    model_config.model.v_inner_boundary = params[2]\n",
    "    model_config.model.v_outer_boundary = 35000*u.km/u.s\n",
    "    model_config.supernova.luminosity_requested = params[1]\n",
    "    model_config.supernova.time_explosion = params[0]\n",
    "    \n",
    "    sim = Simulation.from_config(model_config)\n",
    "    sim.run()\n",
    "    \n",
    "    import pickle\n",
    "\n",
    "    dump = '{}/toy06_t{}_v{}.pickle'.format(pickle_dir, params[0].value, params[2].value)\n",
    "    \n",
    "    with open(dump, 'wb') as dumpfile:\n",
    "        pickle.dump(sim, dumpfile, protocol=0)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blondin_dict, blondin_csv = read_blondin_toymodel('snia_toy06.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blondin_dict['v_inner_boundary'] = '9000 km/s'\n",
    "blondin_dict['v_outer_boundary'] = '35000 km/s'\n",
    "blondin_dict['model_isotope_time_0'] = '0. d'\n",
    "csvy_file = '---\\n{0}\\n---\\n{1}'.format(yaml.dump(blondin_dict, default_flow_style=False), \n",
    "                                        blondin_csv.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('blondin_compare_06.csvy', 'w') as f:\n",
    "    f.write(csvy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.array([5,10,15,20])*u.d\n",
    "velocity_grid = np.arange(10000, 26500, 500)*u.km/u.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = np.array(np.empty((epochs.shape[0]*velocity_grid.shape[0], 3)))\n",
    "model_grid = []\n",
    "\n",
    "for i, epoch in enumerate(epochs):\n",
    "    for j, velocity in enumerate(velocity_grid):\n",
    "        model_grid.append((epoch, lbols[i], velocity-2000*u.km/u.s*i))\n",
    "        \n",
    "print(len(model_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_final_models_plus_pickle(final_params[EPOCH], 'blondin_model_compare_06.yml', \n",
    "                             ATOM_DATA, NTHREADS, PICKLE_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tardis",
   "language": "python",
   "name": "tardis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
